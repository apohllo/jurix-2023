{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal concept-examples system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/apohllo/jurix-2023/blob/main/legal-concepts.ipynb)\n",
    "\n",
    "If running in Colab:\n",
    "1. Copy `requirements.txt` to the main dir.\n",
    "2. Create `data/` dir.\n",
    "3. Copy `questions.json` do `data/`.\n",
    "\n",
    "Please not, that running time of sentence search on V100 takes approx. 1h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - processing of decisions from GDPRHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download decisions from GDPRHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests==2.31.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tqdm==4.65.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: stanza==1.5.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: nltk==3.8.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (3.8.1)\n",
      "Requirement already satisfied: inflect==7.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (7.0.0)\n",
      "Requirement already satisfied: matplotlib==3.7.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.7.2)\n",
      "Requirement already satisfied: pandas==2.0.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: transformers==4.30.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (4.30.2)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: elasticsearch==8.8.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (8.8.2)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: datasets==2.13.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (2.13.1)\n",
      "Requirement already satisfied: accelerate==0.20.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (0.20.3)\n",
      "Requirement already satisfied: evaluate==0.4.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (0.4.0)\n",
      "Requirement already satisfied: neptune==1.3.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (1.3.2)\n",
      "Requirement already satisfied: jupytext==1.14.7 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (1.14.7)\n",
      "Requirement already satisfied: jupyterlab==4.0.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (4.0.2)\n",
      "Requirement already satisfied: xformers==0.0.20 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (0.0.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 1)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from requests==2.31.0->-r requirements.txt (line 1)) (2023.5.7)\n",
      "Requirement already satisfied: emoji in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from stanza==1.5.0->-r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: numpy in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from stanza==1.5.0->-r requirements.txt (line 3)) (1.25.1)\n",
      "Requirement already satisfied: protobuf in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from stanza==1.5.0->-r requirements.txt (line 3)) (4.23.4)\n",
      "Requirement already satisfied: six in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from stanza==1.5.0->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from stanza==1.5.0->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: click in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nltk==3.8.1->-r requirements.txt (line 4)) (8.1.4)\n",
      "Requirement already satisfied: joblib in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nltk==3.8.1->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nltk==3.8.1->-r requirements.txt (line 4)) (2023.6.3)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from inflect==7.0.0->-r requirements.txt (line 5)) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from inflect==7.0.0->-r requirements.txt (line 5)) (4.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from pandas==2.0.3->-r requirements.txt (line 7)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from pandas==2.0.3->-r requirements.txt (line 7)) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from scikit-learn==1.3.0->-r requirements.txt (line 8)) (1.11.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from scikit-learn==1.3.0->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: filelock in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from transformers==4.30.2->-r requirements.txt (line 9)) (3.12.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from transformers==4.30.2->-r requirements.txt (line 9)) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from transformers==4.30.2->-r requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from transformers==4.30.2->-r requirements.txt (line 9)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from transformers==4.30.2->-r requirements.txt (line 9)) (0.3.1)\n",
      "Requirement already satisfied: torchvision in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 10)) (0.15.2)\n",
      "Requirement already satisfied: sentencepiece in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 10)) (0.1.99)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from elasticsearch==8.8.2->-r requirements.txt (line 11)) (8.4.0)\n",
      "Requirement already satisfied: notebook in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter==1.0.0->-r requirements.txt (line 12)) (6.5.4)\n",
      "Requirement already satisfied: qtconsole in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter==1.0.0->-r requirements.txt (line 12)) (5.4.3)\n",
      "Requirement already satisfied: jupyter-console in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter==1.0.0->-r requirements.txt (line 12)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter==1.0.0->-r requirements.txt (line 12)) (7.6.0)\n",
      "Requirement already satisfied: ipykernel in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter==1.0.0->-r requirements.txt (line 12)) (6.24.0)\n",
      "Requirement already satisfied: ipywidgets in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter==1.0.0->-r requirements.txt (line 12)) (8.0.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from datasets==2.13.1->-r requirements.txt (line 13)) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from datasets==2.13.1->-r requirements.txt (line 13)) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from datasets==2.13.1->-r requirements.txt (line 13)) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from datasets==2.13.1->-r requirements.txt (line 13)) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from datasets==2.13.1->-r requirements.txt (line 13)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from datasets==2.13.1->-r requirements.txt (line 13)) (3.8.4)\n",
      "Requirement already satisfied: psutil in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from accelerate==0.20.3->-r requirements.txt (line 14)) (5.9.5)\n",
      "Requirement already satisfied: responses<0.19 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from evaluate==0.4.0->-r requirements.txt (line 15)) (0.18.0)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (3.1.32)\n",
      "Requirement already satisfied: PyJWT in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (2.7.0)\n",
      "Requirement already satisfied: backoff in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (2.2.1)\n",
      "Requirement already satisfied: boto3>=1.16.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (1.28.2)\n",
      "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (11.0.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (0.18.3)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (1.3.1)\n",
      "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (3.0.3)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from neptune==1.3.2->-r requirements.txt (line 16)) (1.6.1)\n",
      "Requirement already satisfied: nbformat in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupytext==1.14.7->-r requirements.txt (line 17)) (5.9.1)\n",
      "Requirement already satisfied: toml in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupytext==1.14.7->-r requirements.txt (line 17)) (0.10.2)\n",
      "Requirement already satisfied: markdown-it-py>=1.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupytext==1.14.7->-r requirements.txt (line 17)) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupytext==1.14.7->-r requirements.txt (line 17)) (0.4.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.0.3)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (5.3.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.7.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.23.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (6.3.2)\n",
      "Requirement already satisfied: traitlets in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab==4.0.2->-r requirements.txt (line 18)) (5.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyre-extensions==0.0.29 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from xformers==0.0.20->-r requirements.txt (line 19)) (0.0.29)\n",
      "Requirement already satisfied: typing-inspect in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from pyre-extensions==0.0.29->xformers==0.0.20->-r requirements.txt (line 19)) (0.9.0)\n",
      "Requirement already satisfied: sympy in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (67.8.0)\n",
      "Requirement already satisfied: wheel in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (0.38.4)\n",
      "Requirement already satisfied: cmake in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (3.26.4)\n",
      "Requirement already satisfied: lit in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (16.0.6)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from boto3>=1.16.0->neptune==1.3.2->-r requirements.txt (line 16)) (1.31.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from boto3>=1.16.0->neptune==1.3.2->-r requirements.txt (line 16)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from boto3>=1.16.0->neptune==1.3.2->-r requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: bravado-core>=5.16.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from bravado<12.0.0,>=11.0.0->neptune==1.3.2->-r requirements.txt (line 16)) (5.17.1)\n",
      "Requirement already satisfied: msgpack in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from bravado<12.0.0,>=11.0.0->neptune==1.3.2->-r requirements.txt (line 16)) (1.0.5)\n",
      "Requirement already satisfied: simplejson in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from bravado<12.0.0,>=11.0.0->neptune==1.3.2->-r requirements.txt (line 16)) (3.19.1)\n",
      "Requirement already satisfied: monotonic in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from bravado<12.0.0,>=11.0.0->neptune==1.3.2->-r requirements.txt (line 16)) (1.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 13)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 13)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 13)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 13)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 13)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from GitPython>=2.0.8->neptune==1.3.2->-r requirements.txt (line 16)) (4.0.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jinja2>=3.0.3->jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.1.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (3.7.1)\n",
      "Requirement already satisfied: argon2-cffi in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (8.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.4.4)\n",
      "Requirement already satisfied: overrides in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (7.3.1)\n",
      "Requirement already satisfied: prometheus-client in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.17.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (25.1.0)\n",
      "Requirement already satisfied: send2trash in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.17.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: platformdirs>=2.5 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-core->jupyterlab==4.0.2->-r requirements.txt (line 18)) (3.8.1)\n",
      "Requirement already satisfied: babel>=2.10 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.12.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (4.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from markdown-it-py>=1.0.0->jupytext==1.14.7->-r requirements.txt (line 17)) (0.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (3.0.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (2.15.1)\n",
      "Requirement already satisfied: tinycss2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from nbformat->jupytext==1.14.7->-r requirements.txt (line 17)) (2.17.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from pydantic>=1.9.1->inflect==7.0.0->-r requirements.txt (line 5)) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.1.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from pydantic>=1.9.1->inflect==7.0.0->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (8.14.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (1.5.6)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 12)) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 12)) (3.0.8)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 12)) (3.0.39)\n",
      "Requirement already satisfied: ipython-genutils in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 12)) (2.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (1.3.0)\n",
      "Requirement already satisfied: webencodings in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: jsonref in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.3.2->-r requirements.txt (line 16)) (1.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune==1.3.2->-r requirements.txt (line 16)) (5.0.0)\n",
      "Requirement already satisfied: backcall in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (2023.6.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.29.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.8.10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-json-logger>=2.0.4 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.1.1)\n",
      "Requirement already satisfied: wcwidth in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter==1.0.0->-r requirements.txt (line 12)) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->-r requirements.txt (line 12)) (2.4.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from sympy->torch>=1.3.0->stanza==1.5.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from typing-inspect->pyre-extensions==0.0.29->xformers==0.0.20->-r requirements.txt (line 19)) (1.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: fqdn in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.4)\n",
      "Requirement already satisfied: uri-template in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (1.13)\n",
      "Requirement already satisfied: rfc3987 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (1.3.8)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (1.15.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages (from isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab==4.0.2->-r requirements.txt (line 18)) (1.2.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take into account only decisions related to articles 44-46 of GDPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "API_ENPOINT=\"https://gdprhub.eu/api.php\"\n",
    "\n",
    "category_titles = [(\"Category:Article_44_GDPR\",\"44\"),  \n",
    "                   (\"Category:Article_45_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(1)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(2)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(3)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(4)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(5)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(6)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(7)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(8)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_45(9)_GDPR\",\"45\"),\n",
    "                   (\"Category:Article_46_GDPR\",\"46\"),\n",
    "                   (\"Category:Article_46(1)_GDPR\",\"46\"),\n",
    "                   (\"Category:Article_46(2)_GDPR\",\"46\"),\n",
    "                   (\"Category:Article_46(3)_GDPR\",\"46\"),\n",
    "                   (\"Category:Article_46(4)_GDPR\",\"46\"),\n",
    "                   (\"Category:Article_46(5)_GDPR\",\"46\"),\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(page_id):\n",
    "    response = requests.get(API_ENPOINT + f\"?action=query&pageids={page_id}&format=json&prop=revisions&rvslots=*&rvprop=content&formatversion=2\")\n",
    "    json_data = response.json()\n",
    "    return re.sub(r\"\\\\n\", \"\\n\", json_data['query']['pages'][0]['revisions'][0]['slots']['main']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API paginates the result, so we have to walk through all pages to get all relevant decisions. \n",
    "\n",
    "Please not that some of the decisions are duplicated, as they might belong to multiple categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_44_GDPR 44\n",
      "Processing Category:Article_44_GDPR 44\n",
      "Processing Category:Article_44_GDPR 44\n",
      "Processing Category:Article_44_GDPR 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:13<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45_GDPR 45\n",
      "Processing Category:Article_45_GDPR 45\n",
      "Processing Category:Article_45_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(1)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(2)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 36054.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(3)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(4)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(5)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(6)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(7)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(8)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_45(9)_GDPR 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_46_GDPR 46\n",
      "Processing Category:Article_46_GDPR 46\n",
      "Processing Category:Article_46_GDPR 46\n",
      "Processing Category:Article_46_GDPR 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:12<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_46(1)_GDPR 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_46(2)_GDPR 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_46(3)_GDPR 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 24456.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_46(4)_GDPR 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category:Article_46(5)_GDPR 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for category_title, category_id in category_titles:\n",
    "    items = []\n",
    "    continue_query = \"\"\n",
    "    while(True):\n",
    "        print(f\"Processing {category_title} {category_id}\")\n",
    "        response = requests.get(API_ENPOINT + f\"?action=query&prop=categories&format=json&list=categorymembers&cmtitle={category_title}{continue_query}\")\n",
    "        json_data = response.json()\n",
    "        for item in json_data['query']['categorymembers']:\n",
    "            items.append(item)\n",
    "\n",
    "        if('continue' not in json_data):\n",
    "            break\n",
    "\n",
    "        continue_id = json_data['continue']['cmcontinue']\n",
    "        continue_query = f\"&cmcontinue={continue_id}\"\n",
    "    for item in tqdm.tqdm(items):\n",
    "        if(item['ns'] == 0):\n",
    "            # regular page\n",
    "            id = item['pageid']\n",
    "            directory = f\"data/gdprhub/art-{category_id}/\"\n",
    "            if(not os.path.exists(\"data/gdprhub\")):\n",
    "                os.mkdir(\"data/gdprhub\")\n",
    "            if(not os.path.exists(directory)):\n",
    "                os.mkdir(directory)\n",
    "            with open(directory + f\"{id}.txt\", \"w\") as output:\n",
    "                output.write(get_text(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract content of decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structure(text):\n",
    "    section = []\n",
    "    structure = {\"preamble\": section}\n",
    "    \n",
    "    for line in text:\n",
    "        if(re.match(r\"^={1,3}[^=]\", line)):\n",
    "            match = re.match(r\"^={1,3}([^=]+)={1,3}\", line)\n",
    "            section_name = match[1].strip()\n",
    "            section = []\n",
    "            structure[section_name] = section\n",
    "        else:\n",
    "            section.append(line)\n",
    "\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parts(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    infobox = []\n",
    "    description = []\n",
    "    translation = []\n",
    "    # 0 init state\n",
    "    # 1 bbox\n",
    "    # 2 description\n",
    "    # 3 translation\n",
    "    state = 0 \n",
    "\n",
    "    for line in lines:\n",
    "        if(len(line) == 0):\n",
    "            continue\n",
    "\n",
    "        if(re.match(r\"^{{\", line)):\n",
    "            state = 1\n",
    "        elif(re.match(r\"^[|]?}}\", line)):\n",
    "            state = 2\n",
    "            continue\n",
    "        elif(re.match(r\"^<pre>\", line)):\n",
    "            state = 3\n",
    "            continue\n",
    "        elif(re.match(r\"<\\/pre>\", line)):\n",
    "            state = 0\n",
    "\n",
    "        if(state == 1):\n",
    "            infobox.append(line)\n",
    "        elif(state == 2):\n",
    "            description.append(line)\n",
    "        elif(state == 3):\n",
    "            translation.append(line)\n",
    "\n",
    "\n",
    "    return {\"infobox\": infobox, \"description\": extract_structure(description), \"translation\": translation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(path, processor, key_path):\n",
    "    text = \"\"\n",
    "    with open(path) as input:\n",
    "        text = input.read()\n",
    "    parts = extract_parts(text)\n",
    "    \n",
    "    item = parts\n",
    "    for key in key_path:\n",
    "        try:\n",
    "            item = item[key]\n",
    "        except KeyError:\n",
    "            return []\n",
    "    return processor.extract_sentences(item).sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza \n",
    "\n",
    "class StanzaProcessor:\n",
    "    def __init__(self):\n",
    "        self.pipeline = stanza.Pipeline(lang='en', processors='tokenize')\n",
    "\n",
    "    def extract_sentences(self, text):\n",
    "        return self.pipeline(\" \".join(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract individual sentences from the GDPRHub decisions. We take into account only `Holding` and `Facts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 17:13:18 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab76858ed58407eba43be5629186a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 17:13:18 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2023-09-28 17:13:18 INFO: Using device: cuda\n",
      "2023-09-28 17:13:18 INFO: Loading: tokenize\n",
      "2023-09-28 17:13:22 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = {}\n",
    "file_names = set()\n",
    "processor = StanzaProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/gdprhub/art-44/6090.txt 20\n",
      "data/gdprhub/art-44/5743.txt 52\n",
      "data/gdprhub/art-44/6174.txt 26\n",
      "data/gdprhub/art-44/4122.txt 20\n",
      "data/gdprhub/art-44/3423.txt 26\n",
      "data/gdprhub/art-44/3240.txt 7\n",
      "data/gdprhub/art-44/5359.txt 64\n",
      "data/gdprhub/art-44/5093.txt 44\n",
      "data/gdprhub/art-44/4253.txt 33\n",
      "data/gdprhub/art-44/5399.txt 18\n",
      "data/gdprhub/art-44/5627.txt 28\n",
      "data/gdprhub/art-44/5938.txt 18\n",
      "data/gdprhub/art-44/4186.txt 10\n",
      "data/gdprhub/art-44/5526.txt 36\n",
      "data/gdprhub/art-44/2804.txt 44\n",
      "data/gdprhub/art-44/6198.txt 19\n",
      "data/gdprhub/art-44/5028.txt 25\n",
      "data/gdprhub/art-44/3408.txt 14\n",
      "data/gdprhub/art-44/5716.txt 49\n",
      "data/gdprhub/art-44/4486.txt 41\n",
      "data/gdprhub/art-44/5996.txt 24\n",
      "data/gdprhub/art-44/6092.txt 18\n",
      "data/gdprhub/art-44/6091.txt 20\n",
      "data/gdprhub/art-44/5110.txt 30\n",
      "data/gdprhub/art-44/3233.txt 16\n",
      "data/gdprhub/art-44/4628.txt 32\n",
      "data/gdprhub/art-44/5953.txt 12\n",
      "data/gdprhub/art-44/3180.txt 27\n",
      "data/gdprhub/art-44/6087.txt 22\n",
      "data/gdprhub/art-44/3241.txt 29\n",
      "data/gdprhub/art-44/5914.txt 34\n",
      "data/gdprhub/art-45/2575.txt 5\n",
      "data/gdprhub/art-45/5624.txt 27\n",
      "data/gdprhub/art-45/2875.txt 43\n",
      "data/gdprhub/art-45/3900.txt 4\n",
      "data/gdprhub/art-45/5944.txt 29\n",
      "data/gdprhub/art-45/5288.txt 17\n",
      "data/gdprhub/art-45/3659.txt 48\n",
      "data/gdprhub/art-45/5101.txt 8\n",
      "data/gdprhub/art-46/5310.txt 24\n",
      "data/gdprhub/art-46/6188.txt 19\n",
      "data/gdprhub/art-46/5947.txt 6\n",
      "data/gdprhub/art-46/5956.txt 42\n",
      "data/gdprhub/art-46/4976.txt 5\n",
      "data/gdprhub/art-46/5506.txt 29\n",
      "data/gdprhub/art-46/5396.txt 15\n",
      "data/gdprhub/art-46/4353.txt 13\n",
      "data/gdprhub/art-46/1515.txt 8\n",
      "data/gdprhub/art-46/4622.txt 39\n",
      "1239\n",
      "1178\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for category_id in [\"44\", \"45\", \"46\"]:\n",
    "    for idx, fname in enumerate(glob.glob(f\"data/gdprhub/art-{category_id}/*.txt\")):\n",
    "        file_name = fname.split(\"/\")[-1]\n",
    "        if file_name in file_names:\n",
    "            continue\n",
    "        file_names.add(file_name)\n",
    "        files[fname] = []\n",
    "        files[fname][0:0] = list(get_sentences(fname, processor, ['description', 'Holding']))\n",
    "        files[fname][0:0] = list(get_sentences(fname, processor, ['description', 'Facts']))\n",
    "\n",
    "sentence_objects = {}\n",
    "sentences = []\n",
    "for idx,fname in enumerate(files):\n",
    "    print(fname, len(files[fname]))\n",
    "    sentences[0:0] = [s.text for s in files[fname]]\n",
    "    sentence_objects.update({(s.text, (s,fname,i)) for i,s in enumerate(files[fname]) if s.text not in sentence_objects})\n",
    "    \n",
    "    \n",
    "print(len(sentences))\n",
    "print(len(sentence_objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 - find sentences that match the questions (slow!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load questions generated by ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 55\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = \"data/\"\n",
    "\n",
    "items = []\n",
    "\n",
    "with open(f\"{path}questions.jsonl\") as input:\n",
    "    for idx, line in enumerate(input):\n",
    "        if(len(line.strip()) == 0):\n",
    "            continue\n",
    "        items.append(json.loads(line))\n",
    "\n",
    "print(f\"Number of questions: {len(items)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load the model trained in the experiment. This is AlBERT-xxl-v1 trained on SQuAD 2.0 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735ff5ad6f4c474fb1044361918ebef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/914 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d42bb95d1d479dae4d1bcb5cc813f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/890M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5939a0915794a8d8b6d3541895fb22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292cd54aeff74afb8abb181d5f338d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"apohllo/albert-xxl-squad-sentences\", num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"apohllo/albert-xxl-squad-sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Add device=0 if you want to use GPU!\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, batch_size=16, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_results(question, sentences, classifier, top_k=5):\n",
    "    samples = [{\"text\": s, \"text_pair\": question} for s in sentences]\n",
    "    results = classifier(samples)\n",
    "    \n",
    "    results = [(idx, r[\"score\"]) if r[\"label\"] == 'LABEL_1' else (idx, 1 - r[\"score\"]) \n",
    "            for idx, r in enumerate(results)]\n",
    "    \n",
    "    keys_values = sorted(results, key=lambda e: -e[1])[:top_k]\n",
    "    return [(v,sentences[k]) for k,v in keys_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On CPU this will run for hours! Albert-XXL is a pretty large model.\n",
    "One questions search takes **~40s** on **A100**.\n",
    "Total runningtime is approx. **40min**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████████████████████▎                                                                                                                                        | 10/55 [07:09<32:27, 43.28s/it]/net/people/plgrid/plgapohl/.conda/envs/exaile/lib/python3.11/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 55/55 [39:19<00:00, 42.90s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{path}/sentences.jsonl\", \"w\") as output:\n",
    "    for item in tqdm.tqdm(items):\n",
    "        results = top_results(item[\"question\"], sentences, classifier, top_k=10)\n",
    "        results = [{\"score\":v, \"sentence\":s} for v,s in results]\n",
    "        item[\"sentences\"] = results\n",
    "        output.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 - answer the questions using Flan-T5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-large\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "generator = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, batch_size=16) #, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"data/sentences.jsonl\") as input:\n",
    "    for line in input:\n",
    "        data.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [01:30,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "context_length = 1\n",
    "\n",
    "# We have selected some sentences below the threshold to see how the model works for them\n",
    "additional_sentences = set([(16,0), (25,0), (39,0), (41,0)])\n",
    "\n",
    "# The threshold was selected to get equal error rate\n",
    "threshold = 0.65\n",
    "\n",
    "with open(\"data/answers.jsonl\", \"w\") as json_output:\n",
    "    for i_idx, item in tqdm.tqdm(enumerate(data)):\n",
    "        for s_idx, sentence in enumerate(item['sentences']):\n",
    "            if sentence['score'] > threshold or (i_idx + 1, s_idx) in additional_sentences:\n",
    "                #print(i_idx, s_idx, \"%.3f\" % sentence['score'])\n",
    "                sentence_object, fname, sentence_index = sentence_objects[sentence['sentence']]\n",
    "                context = []\n",
    "                #print(fname, sentence_index)\n",
    "                if sentence_index - context_length >= 0:\n",
    "                    for i in range(context_length):\n",
    "                        context.append(files[fname][sentence_index - context_length + i])\n",
    "                context.append(sentence_object)\n",
    "                if sentence_index + context_length < len(files[fname]):\n",
    "                    for i in range(context_length):\n",
    "                        context.append(files[fname][sentence_index + i + 1])\n",
    "\n",
    "                context_text = \"\"\n",
    "                for idx,sentence in enumerate(context):\n",
    "                    context_text += sentence.text + \" \"\n",
    "\n",
    "                tuple = {}\n",
    "                tuple[\"concept\"] = item['concept']\n",
    "                tuple[\"question\"] = item['question']\n",
    "                tuple[\"context\"] = context_text\n",
    "                prompt = f\"Given the information: \\\"{context_text}\\\" answer the following question, starting your answer with yes/no: {item['question']}\"\n",
    "                answer = generator(prompt)[0]['generated_text']\n",
    "                tuple[\"answer\"] = answer\n",
    "                json_output.write(json.dumps(tuple) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4 - summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "concepts = []\n",
    "with open(\"data/answers.jsonl\") as input:\n",
    "    for line in input:\n",
    "        data = json.loads(line)\n",
    "        concept = data[\"concept\"]\n",
    "        answer = data[\"answer\"]\n",
    "        if(re.match(r\"yes\", answer, re.I)):\n",
    "            answer_key = \"positive\"\n",
    "            empty_key = \"negative\"\n",
    "        elif(re.match(r\"no\", answer, re.I)):\n",
    "            answer_key = \"negative\"\n",
    "            empty_key = \"positive\"\n",
    "        else:\n",
    "          print(f\"Warning: unknown answer: {answer}\")\n",
    "          continue\n",
    "\n",
    "        if(len(concepts) > 0 and concepts[-1][\"concept\"] == concept):\n",
    "            concepts[-1][answer_key].append({\"example\": data[\"context\"], \"answer\": data[\"answer\"]})\n",
    "        else:\n",
    "            concepts.append({\"concept\": concept, empty_key: [], answer_key: [{\"example\": data[\"context\"], \"answer\": data[\"answer\"]}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "** Enforceable data subject rights **\n",
      "-- Positive examples --\n",
      "\n",
      "The HDPA identified deficiencies as follows: first of all, the HDPA found that\n",
      "the Ministry never made a detailed investigation on the lawfulness of the\n",
      "processing purposes under [[Article 6 GDPR#4|Article 6(4) GDPR]], in particular\n",
      "with regard to the consent for access to information stored in a user's terminal\n",
      "equipment, when is not necessary to provide the service requested by the user.\n",
      "Regarding the principle of transparency and the right to access by the data\n",
      "subject, according to Article 12 and 14 GDPR, the information provided by the\n",
      "Ministry to the data subjects was not considered appropriate and sufficient. The\n",
      "HDPA found in particular that the provided information was not easy to\n",
      "understand and (lack of accessibility and of clear and simple wording),\n",
      "especially vis-à-vis children.\n",
      "-- Negative examples --\n",
      "\n",
      "It also appeared that the company's files contained several excessive comments\n",
      "related to customers or their health conditions. In addition, people were not\n",
      "properly informed about the processing of their personal data, or about the\n",
      "recording of the conversations they had with the company. In total, following\n",
      "its investigations the CNIL found five breaches of the GDPR: -         Violation\n",
      "of the right to object, Article 21(2) GDPR: no procedure was implemented to\n",
      "ensure effectively that persons who opposed telephone solicitation were no\n",
      "longer called); -         Violation of the principle of data minimization,\n",
      "Article 5(1)(c) GDPR: inadequate and offensive comments or irrelevant comments\n",
      "related to people's health were found in the company's customer file; -        \n",
      "Violation of Articles 12 and 13 GDPR: insufficient information on the processing\n",
      "of data subject’s personal data and their rights; -         Violation of\n",
      "Articles 46 and 49 GDPR:  the controller did not provide appropriate safeguards\n",
      "for data subjects; -         Failure to cooperate with the CNIL, Article 31\n",
      "GDPR.\n",
      "\n",
      "It was therefore necessary for the international agreement, as the legal basis\n",
      "for the transfer, to include appropriate data protection safeguards under\n",
      "[[Article 46 GDPR|Article 46(2)(a) GDPR]]. In this case, the DPA found that the\n",
      "agreement contained no definition of data protection, no retention period, no\n",
      "mention of the rights of data subjects and no mention of appeal mechanisms. The\n",
      "DPA therefore concluded that the Belgian tax authority could not rely on\n",
      "[[Article 96 GDPR|Article 96 GDPR]] to continue transferring data to the US on\n",
      "the basis of the FATCA agreement when that agreement is not in line with the\n",
      "GDPR.\n",
      "\n",
      "In addition, people were not properly informed about the processing of their\n",
      "personal data, or about the recording of the conversations they had with the\n",
      "company. In total, following its investigations the CNIL found five breaches of\n",
      "the GDPR: -         Violation of the right to object, Article 21(2) GDPR: no\n",
      "procedure was implemented to ensure effectively that persons who opposed\n",
      "telephone solicitation were no longer called); -         Violation of the\n",
      "principle of data minimization, Article 5(1)(c) GDPR: inadequate and offensive\n",
      "comments or irrelevant comments related to people's health were found in the\n",
      "company's customer file; -         Violation of Articles 12 and 13 GDPR:\n",
      "insufficient information on the processing of data subject’s personal data and\n",
      "their rights; -         Violation of Articles 46 and 49 GDPR:  the controller\n",
      "did not provide appropriate safeguards for data subjects; -         Failure to\n",
      "cooperate with the CNIL, Article 31 GDPR. As a consequence, the CNIL imposed a\n",
      "fine of EUR 500.000.\n",
      "\n",
      "The AEPD also evaluated the position of the three entities involved in the case,\n",
      "and held that according to the processing agreements that were in place, Amazon\n",
      "Road was the controller responsible for the processing carried out by Amazon\n",
      "India and Accurate Background, and that because these processors were located\n",
      "outside the EEA (in India and the United States respectively), international\n",
      "data transfers were taking place. The AEPD found that, in this case, data\n",
      "subjects' consent to data transfers would not be valid in accordance with\n",
      "[[Article 49 GDPR|Article 49(1) GDPR]]  and [[Article 7 GDPR]], given that\n",
      "consent was required within the contract without an option to refuse, it was not\n",
      "explicit, and no information was given to the data subject regarding the risks\n",
      "of these data transfers. However, the AEPD found that the data transfers were\n",
      "lawful according to [[Article 46 GDPR]], since the SCCs in Amazon's processing\n",
      "agreements included appropriate technical and organisational data protection\n",
      "measures, and Accurate Background was adhered to the EU-US Privacy Shield during\n",
      "the time that the data transfers took place.\n",
      "\n",
      "These law allow for bulk collection of personal data. They do not allow a data\n",
      "subject to enforce any rights before a tribunal. ''With regard to national law\n",
      "relating to collection and processing of data:''   The French Court outlined\n",
      "that Article L. 1462-1 of the public health code provides for the Health Data\n",
      "Hub and the collection of health data from the existing national health data\n",
      "system (as per Article L. 1461-1).\n",
      "\n",
      "The DPA remarks that, according the Schrems II Judgment, the transfer of data to\n",
      "the United States may result in violations of fundamental rights, given that the\n",
      "US legislation allows for access to the data because of national security and\n",
      "public interest reasons. Such inferences are not reasonable, as limitations to\n",
      "fundamental rights are not clearly defined; as there are no clear and precise\n",
      "rules on the application of such measures or minimum requirements to protect\n",
      "against risks of abuse; there is no requirement for a necessity test; and there\n",
      "are no enforceable rights for data subjects or legal remedies. The Portuguese\n",
      "DPA found that the National Institute had not undertaken a sufficient Data\n",
      "Protection Impact Assessment, had not consulted the supervisory authority prior\n",
      "to processing, and had therefore not adopted adequate additional safeguards\n",
      "before using the services of a data processor who was headquartered in the\n",
      "United States.\n",
      "==============================\n",
      "** Effective legal remedies for data subjects **\n",
      "-- Positive examples --\n",
      "\n",
      "The parties still agreed supplementary measures. First, Google has established\n",
      "policies and procedures and a team of qualified lawyers for handling authority\n",
      "requests for user data. Second, Google offers and the controller implemented the\n",
      "Anonymize IP feature and, finally, the controller had applied a redaction script\n",
      "on the website to prevent personal data unintentionally being shared with\n",
      "Google.\n",
      "-- Negative examples --\n",
      "==============================\n",
      "** Legally binding and enforceable instrument **\n",
      "-- Positive examples --\n",
      "-- Negative examples --\n",
      "\n",
      "In its privacy policy the controller simply informed consumers about data\n",
      "transfers to third parties and countries, without any further legal effect. This\n",
      "document did not constitute a legally binding contract offered to customers by\n",
      "the controller, as the Consumer Center suggested. The court also held that the\n",
      "Consumer Center's claim with regard to the cookie banners was unfounded.\n",
      "\n",
      "Under national US law, Google LLC, as a provider of electronic communication\n",
      "services is subject to surveillance by the intelligence agencies and is thus\n",
      "obliged to provide the US government with personal data. According to the\n",
      "Schrems judgment, that the DPA considered up-to-date, this legislation doesn’t\n",
      "meet the requirements of EU law. Fourthly, considering that the SCC’s were not\n",
      "sufficient, the DPA assessed whether the controller and the processor\n",
      "implemented additional safeguards for the data transfers.\n",
      "\n",
      "Under national US law, Google LLC, as a provider of electronic communication\n",
      "services is subject to surveillance by the intelligence agencies and is thus\n",
      "obliged to provide the US government with personal data. According to the\n",
      "Schrems judgment, that the DPA considered up-to-date, this legislation doesn’t\n",
      "meet the requirements of EU law. Fourthly, considering that the SCC’s were not\n",
      "sufficient, the DPA assessed whether the controller and the processor\n",
      "implemented additional safeguards for the data transfers.\n",
      "\n",
      "Under national US law, Google LLC, as a provider of electronic communication\n",
      "services is subject to surveillance by the intelligence agencies and is thus\n",
      "obliged to provide the US government with personal data. According to the\n",
      "Schrems judgment, that the DPA considered up-to-date, this legislation doesn’t\n",
      "meet the requirements of EU law. Fourthly, considering that the SCC’s were not\n",
      "sufficient, the DPA assessed whether the controller and the processor\n",
      "implemented additional safeguards for the data transfers.\n",
      "==============================\n",
      "** Binding corporate rules **\n",
      "-- Positive examples --\n",
      "\n",
      "The parties still agreed supplementary measures. First, Google has established\n",
      "policies and procedures and a team of qualified lawyers for handling authority\n",
      "requests for user data. Second, Google offers and the controller implemented the\n",
      "Anonymize IP feature and, finally, the controller had applied a redaction script\n",
      "on the website to prevent personal data unintentionally being shared with\n",
      "Google.\n",
      "-- Negative examples --\n",
      "\n",
      "First, the Irish DPA ascertained whether US law guaranteed an essentially\n",
      "equivalent level of protection of data protection rights in light of Schrems II.\n",
      "This was excluded by the supervisory authority, especially due to the lack of\n",
      "effective judicial remedies against the violation of data subjects’ fundamental\n",
      "rights by U.S. intelligence agencies and due to the lack of limitations imposed\n",
      "on the latters’ investigation powers. The latest developments in U.S. law (which\n",
      "are supposed to ensure a higher level of protection for data transferred to the\n",
      "U.S.) were deemed insufficient by the Irish DPA, especially since some of the\n",
      "promised reforms have not yet been implemented.\n",
      "==============================\n",
      "** Standard data protection clauses **\n",
      "-- Positive examples --\n",
      "\n",
      "The Norwegian DPA then proceeded to investigate the case and notified the\n",
      "controller asking for information about the investigated facts. In response, the\n",
      "controller stated that after becoming aware of the judgment in the Schrems II\n",
      "case, it reassessed its contract with Google, the processor, and adopted\n",
      "standard contractual clauses (SCCs) as the legal basis for the transfer of data\n",
      "to the US. Furthermore, it claimed that it was taking additional measures to\n",
      "ensure the protection of personal data transferred outside the EU/EEA.\n",
      "\n",
      "According to the website provider and Google LLC, the website controller\n",
      "qualifies as controller ([[Article 4 GDPR#7|Article 4(7) GDPR]]) and Google LLC\n",
      "as processor ([[Article 4 GDPR#8|Article 4(8) GDPR]]) for data processing in\n",
      "connection with Google Analytics. Furthermore, according to the privacy\n",
      "documents provided on the website or included via hyperlink, the website\n",
      "provider and Google LLC entered into standard contractual clauses under\n",
      "[[Article 46 GDPR#2#c|Article 46(2)(c) GDPR]] ([https://eur-lex.europa.eu/legal-\n",
      "content/EN/ALL/?uri=celex%3A32010D0087 Commission Decision2010/87 of\n",
      "05.02.2010]; SCCs) as a mechanism for transfers of personal data with regard to\n",
      "Google Analytics. On 18.08.2020, the data subject (represented by ''noyb'')\n",
      "filed a complaint with the DSB against both the website provider (in its role as\n",
      "data exporter) and Google LLC (in its role as data importer), arguing that both\n",
      "respondents violated Articles 44 et. seqq.\n",
      "\n",
      "They found this to apply to their use of Google Analytics since the agreement\n",
      "was with Google as a US processor of their. With the Privacy Shield now\n",
      "invalidated, the controller entered into standard contractual clauses (SCCs)\n",
      "Module Two with Google on 12 August 2020 for data transfers to the US. However,\n",
      "the controller did not carry out a thorough review of potential third country\n",
      "legislation (a \"transfer impact assessment\"), as it, according to information\n",
      "from Google, was not possible to determine the exact location of processing.\n",
      "\n",
      "This general consent clause also stated that it would exonerate Amazon of any\n",
      "responsibility, damages claims, or other charges related to the processing and\n",
      "transfer of data as far as the law permits it. Amazon Road established an Intra-\n",
      "Group Data Transfer and Processing Agreement with Amazon India and a Data\n",
      "Processing Agreement with Accurate Background, which both included Standard\n",
      "Contractual Clauses (SCCs) with technical and organisational measures required\n",
      "for data processing. Additionally, Accurate Background was adhered to the EU-US\n",
      "Privacy Shield transatlantic data transfer framework.\n",
      "\n",
      "For the use of this tool, the controller transferred users’ personal data to the\n",
      "processor, in the US. The controller and Google had implemented standard\n",
      "contractual clauses (‘SCCs’) within the meaning of [[Article 46 GDPR]]. In 2020,\n",
      "''noyb'' lodged a complaint with the Austrian DPA alleging that the controller\n",
      "breached the provisions of Chapter V GDPR.\n",
      "\n",
      "Meta Ireland had been transferring personal data to the U.S. despite the lack of\n",
      "a valid adequacy decision under [[Article 45 GDPR]] (as both “safe harbor” and\n",
      "its successor “privacy shield” were invalidated by the CJEU in Schrems I and\n",
      "II). While negotiation of a new adequacy decision for EU-U.S. data transfers are\n",
      "ongoing, Meta Ireland claimed to have undertaken data transfers on the basis of\n",
      "standard contractual clauses adopted by the Commission under [[Article 46\n",
      "GDPR#2c|Article 46(2)(c) GDPR]] even before the CJEU passed the Schrems II\n",
      "decision. First, the Irish DPA ascertained whether US law guaranteed an\n",
      "essentially equivalent level of protection of data protection rights in light of\n",
      "Schrems II.\n",
      "-- Negative examples --\n",
      "\n",
      "After establishing this, the Court emphasized that the validity of the SCCs,\n",
      "however, did depend on whether there were effective mechanisms in place that\n",
      "make it possible to ensure compliance with the level of protection required by\n",
      "EU law. Important to note is that here the Court held that the SCCs in\n",
      "themselves did provide for such mechanisms. However, it went on to stress that\n",
      "where these mechanisms cannot be complied with, the transfers of personal data\n",
      "pursuant to these clauses is to be suspended or prohibited.\n",
      "==============================\n",
      "** Competent supervisory authority **\n",
      "-- Positive examples --\n",
      "\n",
      "In other words, the fact that the controller claimed to have no knowledge\n",
      "whether data were transferred to the US by Meta Ireland showed that the\n",
      "controller disregarded its responsibilities under the GDPR. In light of the\n",
      "above, the Danish DPA reprimanded the controller and ordered it to bring its\n",
      "processing activities in compliance with [[Article 25 GDPR|Article 25]],\n",
      "[[Article 5 GDPR|5]] and [[Article 24 GDPR|24 GDPR]]. within a month.\n",
      "-- Negative examples --\n",
      "==============================\n",
      "** Contractual clauses **\n",
      "-- Positive examples --\n",
      "\n",
      "Its servers were located in the EU. Company C included clauses in its offer\n",
      "stating that it would not disclose customer data to any third party, except as\n",
      "necessary to maintain or provide the services, or as necessary to comply with\n",
      "the law or a valid and binding order of a governmental body. After reviewing the\n",
      "offers, the publicly owned company issued a decision where it awarded the\n",
      "contract to Company A, as their evaluation of the price was the most economical.\n",
      "\n",
      "The Municipality, in its capacity as the controller, instructed its processor\n",
      "(Google Ireland) to transfer personal data to a sub-processor (Google LLC) in\n",
      "the United States. The transfer was based on standard data protection clauses\n",
      "pursuant to [[Article 46 GDPR|Article 46(2)(c) GDPR]]. In C-311/18, Schrems II,\n",
      "the CJEU clarified that the use of SCCs does not always constitute \"an adequate\n",
      "means of ensuring the effective protection of the personal data transferred to\n",
      "the third country in question in practice.\n",
      "\n",
      "For the use of this tool, the controller transferred users’ personal data to the\n",
      "processor, in the US. The controller and Google had implemented standard\n",
      "contractual clauses (‘SCCs’) within the meaning of [[Article 46 GDPR]]. In 2020,\n",
      "''noyb'' lodged a complaint with the Austrian DPA alleging that the controller\n",
      "breached the provisions of Chapter V GDPR.\n",
      "-- Negative examples --\n",
      "\n",
      "Examining the decision in light of the provisions of the Charter, the Court held\n",
      "that the requirements of US national security, public interest, and law\n",
      "enforcement do in fact interfere with the fundamental rights of persons whose\n",
      "data is transferred there. These limitations on the protection of personal data\n",
      "were not circumscribed in a way that satisfied requirements that are essentially\n",
      "equivalent to those required under EU law. The principle of proportionality was\n",
      "also not satisfied, in so far as US surveillance programs are not limited to\n",
      "what is ‘strictly necessary’.\n",
      "\n",
      "It considered whether the respondent could rely on any transfer mechanisms under\n",
      "Chapter V. of the GDPR and held:  * The respondent could not rely on an adequacy\n",
      "decision following [[CJEU - C-311/18 - Schrems II|C-311/18]]. * The SCCs\n",
      "concluded between the respondent and Google LLC do not offer an adequate level\n",
      "of protection, because:  ** Google LLC qualifies as an \"''electronic\n",
      "communication service provider''\" under 50 U.S. Code § 1881(b)(4) and is subject\n",
      "to surveillance by US intelligence services, and ** any contractual,\n",
      "organisational and technical measures which Google put into place to complement\n",
      "the SCCs were insufficient as they could not prevent US intelligence services\n",
      "from accessing the data subject's personal data ** Notably, the CNIL rejected\n",
      "Google's argument that any Google Analytics data were pseudonymised,\n",
      "highlighting that Universal Unique Identifiers do not meet the definition of\n",
      "pseudonymisation under [[Article 4 GDPR#5|Article 4(5) GDPR]], as their sole\n",
      "purpose is to identify users. *\n",
      "==============================\n",
      "** Administrative arrangements **\n",
      "-- Positive examples --\n",
      "-- Negative examples --\n",
      "\n",
      "Examining the decision in light of the provisions of the Charter, the Court held\n",
      "that the requirements of US national security, public interest, and law\n",
      "enforcement do in fact interfere with the fundamental rights of persons whose\n",
      "data is transferred there. These limitations on the protection of personal data\n",
      "were not circumscribed in a way that satisfied requirements that are essentially\n",
      "equivalent to those required under EU law. The principle of proportionality was\n",
      "also not satisfied, in so far as US surveillance programs are not limited to\n",
      "what is ‘strictly necessary’.\n",
      "\n",
      "The DPA remarks that, according the Schrems II Judgment, the transfer of data to\n",
      "the United States may result in violations of fundamental rights, given that the\n",
      "US legislation allows for access to the data because of national security and\n",
      "public interest reasons. Such inferences are not reasonable, as limitations to\n",
      "fundamental rights are not clearly defined; as there are no clear and precise\n",
      "rules on the application of such measures or minimum requirements to protect\n",
      "against risks of abuse; there is no requirement for a necessity test; and there\n",
      "are no enforceable rights for data subjects or legal remedies. The Portuguese\n",
      "DPA found that the National Institute had not undertaken a sufficient Data\n",
      "Protection Impact Assessment, had not consulted the supervisory authority prior\n",
      "to processing, and had therefore not adopted adequate additional safeguards\n",
      "before using the services of a data processor who was headquartered in the\n",
      "United States.\n",
      "\n",
      "These law allow for bulk collection of personal data. They do not allow a data\n",
      "subject to enforce any rights before a tribunal. ''With regard to national law\n",
      "relating to collection and processing of data:''   The French Court outlined\n",
      "that Article L. 1462-1 of the public health code provides for the Health Data\n",
      "Hub and the collection of health data from the existing national health data\n",
      "system (as per Article L. 1461-1).\n",
      "\n",
      "The principle of proportionality was also not satisfied, in so far as US\n",
      "surveillance programs are not limited to what is ‘strictly necessary’. It was\n",
      "noted that the provisions in the US surveillance programs neither limited the\n",
      "power they conferred onto national authorities, nor granted data subjects\n",
      "actionable rights before the courts against the US authorities. The Court\n",
      "proceeded to scrutinize the Ombudsperson mechanism that had been in place under\n",
      "the Privacy Shield, stating that it too did not provide data subjects with a\n",
      "cause of action before a body which was fully independent, and that this body\n",
      "was limited in so far as it could not impose rules that were binding on US\n",
      "intelligence services.\n",
      "==============================\n",
      "** Consistency mechanism **\n",
      "-- Positive examples --\n",
      "-- Negative examples --\n",
      "\n",
      "The DPA concluded that Portuguese citizens lack any guarantees in regards to\n",
      "their data being collected by the National Statistical Institute, as US\n",
      "legislation does not offer a similar level of protection than the GDPR. The\n",
      "controller had neither been able to demonstrate that the data is not effectively\n",
      "transferred to the US, not had they implemented any supplementary adequate\n",
      "measures to ensure a similar level of protection, which they are obliged to do\n",
      "as a data controller. Therefore, the CNPD ordered the National Statistical\n",
      "Institute to suspend any processing of personal data for the census in the US or\n",
      "any other third country without adequate levels of protection, within 12 hours\n",
      "of their decision being issued.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "for item in concepts:\n",
    "    print(\"=\" * 30)\n",
    "    print(\"** \" + item[\"concept\"] + \" **\")\n",
    "    print(\"-- Positive examples --\")\n",
    "    for example in item[\"positive\"]:\n",
    "        print(\"\")\n",
    "        print(textwrap.fill(example['example'], 80))\n",
    "    print(\"-- Negative examples --\")\n",
    "    for example in item[\"negative\"]:\n",
    "        print(\"\")\n",
    "        print(textwrap.fill(example['example'], 80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
